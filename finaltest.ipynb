{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "1. 선\n",
    "2. 산포도/산점도\n",
    "3. 막대\n",
    "4. 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Quantity\n",
      "Product          \n",
      "A              20\n",
      "B              35\n"
     ]
    }
   ],
   "source": [
    "# 2 - (1)\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"CustomerID\": [\"C1\", \"C2\", \"C3\", \"C4\"],\n",
    "    \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"Quantity\": [10, 15, 10, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# (2-1) 각 제품(Product)별로 판매된 총 수량(Quantity)을 계산하여 그 결과를 출력\n",
    "product_totals = df.pivot_table(index='Product', values='Quantity', aggfunc='sum')\n",
    "print(product_totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product      A   B\n",
      "CustomerID        \n",
      "C1          10   0\n",
      "C2           0  15\n",
      "C3          10   0\n",
      "C4           0  20\n"
     ]
    }
   ],
   "source": [
    "# 2 - (2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"CustomerID\": [\"C1\", \"C2\", \"C3\", \"C4\"],\n",
    "    \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"Quantity\": [10, 15, 10, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 각 고객(CustomerID)이 구매한 제품(Product)별 총 수량(Quantity)을 계산\n",
    "customer_product_quantity = df.pivot_table(values='Quantity', index='CustomerID', columns='Product', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# 결과 출력\n",
    "print(customer_product_quantity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Quantity\n",
      "Product          \n",
      "A            10.0\n",
      "B            17.5\n"
     ]
    }
   ],
   "source": [
    "# 2 - (3)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"CustomerID\": [\"C1\", \"C2\", \"C3\", \"C4\"],\n",
    "    \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"Quantity\": [10, 15, 10, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 각 제품(Product)별로 평균 구매 수량(Quantity)을 계산하여 그 결과를 출력\n",
    "product_mean_quantity = df.pivot_table(index='Product', values='Quantity', aggfunc='mean')\n",
    "print(product_mean_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 도시에서 최고 온도가 가장 높은 날짜:\n",
      "도시\n",
      "광주    2024-06-01\n",
      "대구    2024-06-01\n",
      "서울    2024-06-02\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/mf4_40q57ldgrc8_67rty2dw0000gn/T/ipykernel_58835/1053742055.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result = df.groupby('도시').apply(find_max_temp_date)\n"
     ]
    }
   ],
   "source": [
    "# 3 apply안에 익명함수 만들기(최고 온도가 가장 높은날짜에) \n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"도시\": [\"서울\", \"서울\", \"대구\", \"광주\"],\n",
    "    \"날짜\": [\"2024-06-01\", \"2024-06-02\", \"2024-06-01\", \"2024-06-01\"],\n",
    "    \"최고 온도\": [28, 30, 32, 29],\n",
    "    \"최저 온도\": [18, 20, 21, 19],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 각 도시에서 최고 온도가 가장 높은 날짜를 찾는 함수\n",
    "def find_max_temp_date(group):\n",
    "    max_temp_date = group.loc[group['최고 온도'].idxmax(), '날짜']\n",
    "    return max_temp_date\n",
    "\n",
    "# apply 함수를 사용하여 각 도시에 대해 함수 적용\n",
    "result = df.groupby('도시').apply(find_max_temp_date)\n",
    "\n",
    "print(\"각 도시에서 최고 온도가 가장 높은 날짜:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             종가  2일 이동 합계\n",
      "날짜                       \n",
      "2024-06-01  100       NaN\n",
      "2024-06-02  102     202.0\n",
      "2024-06-03  101     203.0\n",
      "2024-06-04  105     206.0\n",
      "2024-06-05  107     212.0\n"
     ]
    }
   ],
   "source": [
    "# 4 - 빈칸 적기\n",
    "\n",
    "import pandas as pd\n",
    "# 주어진 데이터프레임\n",
    "data = {\n",
    " '날짜': ['2024-06-01', '2024-06-02', '2024-06-03', '2024-06-04', '2024-06-05'],\n",
    " '종가': [100, 102, 101, 105, 107] }\n",
    "df = pd.DataFrame(data)\n",
    "# '날짜' 열의 데이터를 datetime 형식으로 변환\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "# '날짜' 열을 데이터프레임 df의 인덱스로 설정\n",
    "df.set_index('날짜', inplace=True)\n",
    "# 2일 이동 합계 계산하여 새로운 열 '2일 이동 합계'로 데이터프레임 df에 추가\n",
    "df['2일 이동 합계'] = df['종가'].rolling(window=2).sum()\n",
    "# 최종 데이터프레임 출력\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "\n",
    "1. 결측 데이터의 확인\n",
    "isnull() 및 sum()\n",
    "2. 결측 데이터의 제거\n",
    "dropna()\n",
    "3. 결측 데이터의 대체\n",
    "fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "1. 중복 데이터의 확인\n",
    "duplicated()\n",
    "2. 중복 데이터의 제거\n",
    "drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 예제를 들어도 됨\n",
    "\n",
    "원-핫 인코딩(One-hot encoding)은 범주형 데이터를 머신러닝 알고리즘에 사용할 수 있도록 변환하는 전처리 기법입니다. \n",
    "각 범주형 값을 이진 벡터로 변환하는 방법으로, 데이터의 명목적 정보가 수치적으로 표현되지만 그 값들 간의 순서나 크기가 없는 상태를 유지합니다.\n",
    "\n",
    "예)\n",
    "\n",
    "색상 데이터\n",
    "\n",
    "빨강\n",
    "파랑\n",
    "초록\n",
    "빨강\n",
    "\n",
    "원핫인코딩 후\n",
    "\n",
    "빨강  파랑  초록\n",
    "1     0     0\n",
    "0     1     0\n",
    "0     0     1\n",
    "1     0     0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  City     대구     서울     인천\n",
      "0   서울  False   True  False\n",
      "1   대구   True  False  False\n",
      "2   인천  False  False   True\n",
      "3   서울  False   True  False\n",
      "4   대구   True  False  False\n",
      "5   서울  False   True  False\n"
     ]
    }
   ],
   "source": [
    "# 8 - 결과적기\n",
    "\n",
    "import pandas as pd\n",
    "cities = ['서울', '대구', '인천', '서울', '대구', '서울']\n",
    "df = pd.DataFrame(cities, columns=['City'])\n",
    "encoded = pd.get_dummies(df['City'])\n",
    "df_encoded = pd.concat([df, encoded], axis=1)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID  Product\n",
      "C1          A          10.0\n",
      "C2          B          15.0\n",
      "C3          A          10.0\n",
      "C4          B          20.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"OrderID\": [1, 2, 3, 4],\n",
    "    \"CustomerID\": [\"C1\", \"C2\", \"C3\", \"C4\"],\n",
    "    \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"Quantity\": [10, 15, 10, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# pivot_table()을 사용하여 CustomerID와 Product별 총 구매 수량을 계산\n",
    "pivot_df = df.pivot_table(index='CustomerID', columns='Product', values='Quantity', aggfunc='sum')\n",
    "\n",
    "# stack() 함수를 사용하여 스택하여 MultiIndex Series로 변환\n",
    "stacked_df = pivot_df.stack()\n",
    "print(stacked_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "\n",
    "10. 다음 중 데이터 분석에서 사용하지 않는 데이터 유형은 무엇인가?\n",
    "(a) 범주형 데이터 (b) 연속형 데이터 (c) 이미지 데이터 (4) 시계열 데이터\n",
    "\n",
    "답: (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 \n",
    "\n",
    "데이터 분석 파이프라인의 과정을 올바르게 작성한 것은 무엇인가? \n",
    "\n",
    "(a) 데이터 준비-데이터 탐색-데이터 정제-데이터 분석-데이터 시각화 \n",
    "(b) 데이터 정제-데이터 준비-데이터 탐색-데이터 분석-데이터 시각화 \n",
    "(c) 데이터 정제-데이터 준비-데이터 분석-데이터 탐색-데이터 시각화 \n",
    "(d) 데이터 정제-데이터 준비-데이터 시각화 –데이터 탐색-데이터 분석\n",
    "\n",
    "답: (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "\n",
    "12. 데이터 분석의 모델링(데이터마이닝, 데이터사이언스)에 대한 설명이다. 설명이 가장 잘못 된 것은 무엇인가?\n",
    "(a) 데이터마이닝 모델링은 통계적 모델링이 아니므로 지나치게 통계적 가설이나 유의성에 집 착하지 말아야 한다.\n",
    "(b) 모델링 방법은 여러 가지가 있으므로 모델링 시 반드시 다양한 옵션을 줘서 모델링을 수 행하여 최고의 성과를 도출하여야 한다.\n",
    "(c) 분석 데이터를 학습 및 테스트 데이터로 7:3 또는 8:2 비율로 상황에 맞게 실시한다.\n",
    "(d) 성능에 집착하면 분석 모델링의 주목적인 실무 적용에 반하여 시간을 낭비할 수 있으므로 훈련 및 테스트 성능에 큰 편차가 없고 예상 성능을 만족하면 중단한다.\n",
    "\n",
    "\n",
    "(b) - 교수님 왈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13\n",
    "\n",
    "13. 데이터 탐색의 목적은 데이터를 이해하는 것이다. 다음 중 이에 대한 설명으로 가장 부적 절한 것은?\n",
    "\n",
    "(a) 데이터에 대한 전반적인 이해를 통해 분석 가능한 데이터인지 확인하는 단계이다.\n",
    "(b) 데이터 탐색 과정은 데이터에 포함된 변수의 유형이 어떻게 되는지를 찾아가는 과정이다. \n",
    "(c) 데이터를 시각화하는 것만으로는 결측치나 이상치 식별이 잘되지 않는다.\n",
    "(d) 기계 학습 알고리즘이 학습을 얼마나 잘 하느냐 하는 것은 전적으로 데이터의 품질과 데 이터에 담긴 정보량에 달려 있다.\n",
    "\n",
    "(c) - 교수님 왈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14\n",
    "\n",
    "14. 상관분석이 무엇인지 설명하시오. - 독립변수와 종속변수와 상관이 있는지, corr함수 이용(두변수간 상관이 양수(대각선), 음수(반대방향 대각선)으로 나뉨), 0에 가까울수록 상관없음\n",
    "\n",
    "\n",
    "상관분석(Correlation Analysis)은 두 변수 간의 관계를 측정하는 통계적 기법입니다. \n",
    "상관분석은 주어진 두 변수 사이의 선형 관계의 강도와 방향을 파악하는 데 사용됩니다. \n",
    "이를 통해 한 변수의 변화가 다른 변수에 미치는 영향을 이해하고 예측하는 데 도움이 됩니다.\n",
    "\n",
    "상관계수가 1에 가까울수록 두 변수는 강한 양의 선형 관계를 갖습니다.\n",
    "-1에 가까울수록 두 변수는 강한 음의 선형 관계를 갖습니다.\n",
    "0에 가까울수록 두 변수 간에 선형 관계가 없습니다.\n",
    "\n",
    "상관계수를 계산하기 위해 Pandas의 corr() 함수를 사용할 수 있습니다.\n",
    "양의 상관관계가 있는 경우 대각선 방향으로, 음의 상관관계가 있는 경우 반대 방향으로 나타납니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 - 오차의 제곱의 합을 구한 것 중 가장 적게 나온 가중치를 찾는 것\n",
    "\n",
    "관찰된 데이터와 모델 간의 오차의 제곱의 합을 최소화하여 모델의 파라미터를 추정하는 회귀 분석 기법입니다.\n",
    "오차(잔차)의 크기가 작아지면 모델이 관찰된 데이터를 더 잘 설명할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 \n",
    "기계 학습 기반 예측 분석 모델링의 개발 과정\n",
    "\n",
    "1. 데이터 수집\n",
    "2. 데이터 전처리\n",
    "3.데이터 탐색 및 시각화\n",
    "4. 피처 선택 및 추출\n",
    "5. 모델 선택\n",
    "6. 모델 학습\n",
    "7. 모델 평가\n",
    "8. 모델 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17\n",
    "기계 학습 모델에서 최적화(Optimization)와 일반화(Generalization)의 차이점을 데이터 관점에서 설명하시오.\n",
    "\n",
    "모델 구축할때 사용 - 학습용 데이터 - 트레인\n",
    "모델 구축 후 모델 평가 - 테스트용 데이터 - 테스트\n",
    "\n",
    "최적화 - 모델을 학습 데이터에 가장 잘 적합하도록 만드는 과정. 학습 데이터에 맞추어 모델을 과적합 하지 않도록 주의해야함.\n",
    "일반화 - 훈련 세트로 학습한 모델이 테스트 세트에 대해 정확히 예측하도록 하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18\n",
    "머신러닝 학습 중 지도학습에 대해 예제를 가지고 설명하시오.\n",
    "\n",
    "학습용 데이터 집합: 정답이 표시된 수백 개의 문제를 모아놓은 문제집\n",
    "• 지도학습이란 이 문제집을 컴퓨터에 주고 학습시키는 것과 같다.\n",
    "• 컴퓨터는 이 수백 개의 문제를 나름의 풀이방법으로 스스로 풀어본 다음, 정답을 이용하여 얼마나 맞혔는지 채점한다. \n",
    "그런 다음 풀이 방법을 스스로 조금씩 바꾸어 보면서 풀이와 채점을 반복한다. 이 과정을 반복하는 것이 지도학습이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19\n",
    "선형 회귀모델의 성능을 평가하는 방법에 대해 적으시오.\n",
    "\n",
    "1. MSE(평균제곱오차)를 구한다. MSE가 작을수록 모델 예측이 정확하다.\n",
    "2. MAE(평균절대오차)를 구한다. MAE가 작을수록 모델 예측이 정확하다.\n",
    "3. R^2(결정계수)를 구한다. 최댓값은 1이며 1에 가까울수록 모델 예측이 정확하다.\n",
    "4. 잔차분포분석을 한다. 이상치나 패턴이 없는 무작위 분포가 바람직하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20\n",
    "분류 모델을 평가하는 정확도(accuracy)에 대해 설명하시오.\n",
    "\n",
    "\n",
    "전체 샘플 중 맞게 예측한 샘플 수의 비율을 뜻한다. \n",
    "전체 샘플 중 맞게 예측한 샘플 수의 비율을 뜻한다. \n",
    "일반적으로 학습에서 최적화 목적함수로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21\n",
    "\n",
    "검토 필요 \n",
    "##################################################################\n",
    "(1) \n",
    "회귀, 분류\n",
    "##################################################################\n",
    "(2) - 예) model = LinearRegression()\n",
    "Scikit-learn\n",
    "##################################################################\n",
    "(3)\n",
    "fit()\n",
    "##################################################################\n",
    "(4)\n",
    "model.predict()\n",
    "##################################################################\n",
    "(5)\n",
    "train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22\n",
    "교차 검증(Cross-validation)은 무엇이며, 왜 중요한가요?\n",
    "\n",
    "데이터셋을 여러 개의 폴드로 나누어 각 폴드에 대해 모델을 학습하고 평가함으로써 모델의 일반화 성능을 추정하는 기법이다.\n",
    "\n",
    "-중요한 이유-\n",
    "모델의 성능을 정확하게 평가할 수 있다.\n",
    "과적합을 방지할 수 있다.\n",
    "하이퍼파라미터 튜닝에 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23\n",
    "\n",
    "다음 중 가장 일반적인 분류 문제 평가 지표는 무엇인가요? \n",
    "(a) AUC-ROC 곡선 아래 면적 \n",
    "(b) R 제곱 값\n",
    "(c) 평균 제곱 오차 (MSE) \n",
    "(d) 정확도 (Accuracy)\n",
    "\n",
    "(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24\n",
    "24. 다음 중 overfitting을 방지하기 위한 방법이 아닌 것은? \n",
    "(a) 더 많은 데이터 수집 \n",
    "(b) 모델의 복잡성 증가\n",
    "(c) 특성 선택 (Feature selection) \n",
    "(d) 교차 검증 사용\n",
    "\n",
    "(b) - 교수님 왈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25\n",
    "25. 다음 중 기계 학습 모델의 일반화를 평가하는 데 가장 적합한 방법은 무엇인가요? \n",
    "(a) 훈련 데이터셋의 정확도 평가 \n",
    "(b) 테스트 데이터셋의 정확도 평가\n",
    "(c) 모델의 학습 속도 평가 \n",
    "(d) 모델의 파라미터 수 평가\n",
    "\n",
    "(b) - 교수님 왈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26\n",
    "26. 다음 중 overfitting을 나타내는 전형적인 양상은 무엇인가요?\n",
    "(a) 훈련 데이터와 테스트 데이터에서 모두 높은 정확도를 보인다.\n",
    "(b) 훈련 데이터에서 매우 높은 정확도를 보이지만 테스트 데이터에서 낮은 정확도를 보인다. \n",
    "(c) 훈련 데이터에서 낮은 정확도를 보이고 테스트 데이터에서 높은 정확도를 보인다.\n",
    "(d) 훈련 데이터와 테스트 데이터에서 모두 낮은 정확도를 보인다.\n",
    "\n",
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27\n",
    "27. 다음 중 기계 학습 모델의 일반화 성능을 향상시키는 방법으로 적절하지 않은 것은 무엇 인가요?\n",
    "(a) 더 많은 훈련 데이터를 수집한다. \n",
    "(b) 모델의 복잡도를 증가시킨다.\n",
    "(c) 정규화를 사용한다. \n",
    "(d) 교차 검증을 수행한다.\n",
    "\n",
    "(b) - 교수님 왈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28\n",
    "28. 다음 중 overfitting을 피하기 위해 사용할 수 있는 기술이 아닌 것은?\n",
    "(a) 정규화 (Regularization) \n",
    "(b) 원-핫 인코딩(One-hot encoding) \n",
    "(c) 데이터 증강 (Data Augmentation) \n",
    "(d) 모델 파라미터 최적화\n",
    "\n",
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29\n",
    "29. 다음은 회귀 분석 모델의 성능 평가 지표인 MSE(Mean Squared Error), MAE(Mean Absolute Error), R2(Coefficient of Determination)에 관련된 문제이다.\n",
    "\n",
    "##################################################################\n",
    "(1) MSE에 대해 설명하시오.\n",
    "\n",
    "회귀 분석 모델의 성능을 평가하기 위한 지표 중 하나로, 실제값과 예측값의 차이를 제곱한 후 평균을 내는 값.\n",
    "##################################################################\n",
    "(2) MAE에 대해 설명하시오.\n",
    "\n",
    "회귀 분석 모델의 성능을 평가하기 위한 지표 중 하나로, 실제값과 예측값의 차이의 절댓값을 평균한 값.\n",
    "##################################################################\n",
    "(3) 이상치가 많은 데이터 셋에서는 MSE 또는 MAE 중 어느 것을 사용하는 것이 더 유리 한지 적으시오.\n",
    "\n",
    "MAE - 교수님 왈\n",
    "##################################################################\n",
    "(4) R2에 대해 설명하고, R2 값이 1, 0, 음수일 때 각각 어떤 의미인지 설명하시오.\n",
    "\n",
    "회귀 모델의 적합도를 나타내는 지표로, 실제 종속 변수의 변동량 중 모델이 설명하는 비율을 의미.\n",
    "1인 경우: 모델이 모든 데이터 변동을 설명한다는 것을 의미.\n",
    "0인 경우: 모델이 모든 데이터 변동을 설명하지 못한다는 것을 의미.\n",
    "음수인 경우: 모델이 상수 모델보다 성능이 낮다는 것을 의미. \n",
    "##################################################################\n",
    "(5) 다음 중 MSE의 특징으로 옳지 않은 것은?\n",
    "\n",
    "(a) 모든 오차의 제곱을 평균한 값이다. \n",
    "(b) 큰 오차에 대해 패널티를 더 많이 부여한다.\n",
    "(c) 오차의 절댓값을 평균한 값이다. \n",
    "(d) 값이 작을수록 모델의 예측 성능이 좋다는 의미이다.\n",
    "\n",
    "(c) - 교수님 왈\n",
    "##################################################################\n",
    "(6) MAE의 장점으로 올바른 것은?\n",
    "\n",
    "(a) 큰 오차에 대해 더 큰 패널티를 준다. \n",
    "(b) 모든 오차를 제곱하여 계산한다. \n",
    "(c) 이상치에 덜 민감하다. \n",
    "(d) R2 값이 항상 1에 가까워진다.\n",
    "\n",
    "(c)\n",
    "##################################################################\n",
    "(7) R2 값이 0.9인 경우, 모델의 성능에 대해 올바르게 해석한 것은?\n",
    "\n",
    "(a) 모델이 예측을 완벽하게 수행한다. \n",
    "(b) 모델이 데이터 변동의 90%를 설명한다.\n",
    "(c) 모델이 90%의 데이터를 정확하게 예측한다. \n",
    "(d) 모델이 예측 오차의 90%를 제거한다.\n",
    "\n",
    "(b)\n",
    "##################################################################\n",
    "(8) R2 값이 음수인 경우, 이는 무엇을 의미하는가?\n",
    "\n",
    "(a) 모델이 예측을 완벽하게 수행한다. \n",
    "(b) 모델이 데이터 변동의 0%를 설명한다. \n",
    "(c) 모델이 상수 모델보다 성능이 낮다. \n",
    "(d) 모델이 예측 오차의 100%를 제거한다.\n",
    "\n",
    "(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30\n",
    "다음은 회귀 분석에 관한 문제에 대해 답하시오.\n",
    "#################################################################\n",
    "(1) 다음 중 선형 회귀 분석의 기본 가정에 해당하지 않는 것은? \n",
    "(a) 선형성 (Linearity) (b) 독립성 (Independence)\n",
    "(c) 정규성 (Normality) (d) 이산성 (Discreteness)\n",
    "\n",
    "(d)\n",
    "#################################################################\n",
    "(2) 회귀분석의 정의가 올바르지 않은 것은?\n",
    "(a) 1개 또는 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 머신러닝 기법이다.\n",
    "(b) 변수들 사이의 상관관계를 밝히고 모형을 적합하여 관심이 있는 변수를 예측하거나 추론하기 위한 분석 방법이다.\n",
    "(c) 독립변수의 개수가 1개이면 단순 선형회귀분석, 독립변수의 개수가 두 개 이상이면 다중선형회귀분석으로 분석할 수 있다.\n",
    "(d) 회귀분석에서 Python의 통계 모델을 구축하고 평가하는 데 사용되는 statsmodels의 OLS(Ordinary Least Squares) 모델을 사용하여 선형 회귀 분석을 수행할 수 있다.\n",
    "\n",
    "4는 맞는 말- 교수님 왈\n",
    "(a) - 머신러닝이 아닌 통계적 분석 방법\n",
    "##################################################################\n",
    "(3) 선형 회귀 모델링의 성능을 평가할 때 사용되는 지표가 아닌 것은? \n",
    "(a) MSE (b) MAE \n",
    "(c) R2  (d) ROC-AUC\n",
    "\n",
    "(d) - 분류 모델 성능 평가\n",
    "##################################################################\n",
    "(4) 선형 회귀 통계모델의 요약(summary)을 통해 해석할 수 있는 지표가 아닌 것은? \n",
    "\n",
    "(a) 회귀계수 (b) p-value \n",
    "(c) R-제곱  (d) MSE\n",
    "\n",
    "(d) - 머신러닝에서만. 교수님 왈\n",
    "##################################################################\n",
    "(5) 단순 선형 회귀분석 통계모델링 OLS에 대한 설명이 올바르지 않은 것은? \n",
    "\n",
    "(a) 하나의 독립변수가 종속변수에 미치는 영향을 추정할 수 있는 통계기법이다. \n",
    "(b) 단순 선형 회귀 추정 수식은 이다.\n",
    "(c) 단순 선형 회귀 수식 의 계수의 p>|t| 값은 일반적으로 0.05보다 작으면 해당 회귀계수는 통계적으로 유의미하다고 판단한다.\n",
    "(d) R-제곱 (R-squared)은 모델의 설명력을 나타낸다. 즉, 독립 변수가 종속 변수의 변동성을 얼마나 설명하는지를 보여준다.\n",
    "(e) R-제곱 값이 1에 가까울수록 모델이 데이터를 잘 설명을 못함을 의미한다.\n",
    "(f) 회귀계수의 추정은 최소제곱법, 즉 잔차제곱합이 가장 작은 선을 구하는 것을 의미한다. (g) 회귀계수가 0이면 입력변수와 종속변수 사이에는 아무런 관계가 없음을 의미한다.\n",
    "\n",
    "(e) - 교수님왈\n",
    "##################################################################\n",
    "(6) 다음 OLS 선형회귀 모델링의 요약 결과표이다. 이 표를 보고 이 모델의 성능을 해석 하시오.\n",
    "\n",
    "이 회귀 모델은 매우 높은 R-squared값과 높은 Adj. R-squared 값으로 데이터를 잘 설명하고 있으며, 광고비가 매출액에 유의미한 영향을 미친다고 결론지을 수 있음. \n",
    "모든 회귀 계수가 통계적으로 유의미하다는 것이 낮은 p-value 값을 통해 확인됨. \n",
    "따라서, 이 모델은 광고비와 매출액 간의 관계를 설명하는 데 매우 적합하다고 볼 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31 - 반드시 나옴\n",
    "[코딩 문제] 주어진 데이터를 이용하여 로지스틱 분류 회귀(Logistic regression) 모델링 을 코딩하시오. \n",
    "아래 문제별 코드를 실행하면 로지스틱 회귀 분류 모델링의 각 단계를 확인할 수 있도록 코딩하시오.\n",
    "##################################################################\n",
    "(1) 주어진 데이터를 사용하여 로지스틱 회귀 모델을 생성하고 지도학습으로 훈련하시오.\n",
    "아래 참고\n",
    "##################################################################\n",
    "(2)\n",
    "리니어리그레션에서 했던거 그대로 이용(coef_, intercept_ 이용)\n",
    "아래 참고\n",
    "##################################################################\n",
    "(3)\n",
    "리니어리그레션(model.predict() 하고 테스트값 집어넣기)\n",
    "아래 참고\n",
    "##################################################################\n",
    "(4)\n",
    "아래 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회귀 계수: [[1.04742396]]\n"
     ]
    }
   ],
   "source": [
    "# (31-1) 로지스틱 회귀 모델 생성 및 훈련\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 주어진 데이터\n",
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "# (31-1) 로지스틱 회귀 모델 생성 및 훈련\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"회귀 계수:\", coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y절편: [-2.53531358]\n"
     ]
    }
   ],
   "source": [
    "# (31-2) 로지스틱 회귀 모델의 회귀 계수와 y절편 출력\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 주어진 데이터\n",
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "# (31-2) 로지스틱 회귀 모델의 회귀 계수와 y절편 출력\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(\"y절편:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값: [1 1]\n"
     ]
    }
   ],
   "source": [
    "# (31-3) 주어진 특성 데이터 사용하여 예측 값 추정\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 주어진 데이터\n",
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "# (31-3) 주어진 특성 데이터 사용하여 예측 값 추정\n",
    "X_test = np.array([[6], [7]])\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"예측 값:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# (31-4) 주어진 특성 데이터를 사용하여 문제 (31-1)에서 얻은 로지스틱 회귀 모델의 분류 성 능 평가를 confusion matrix와 classification_report을 활용하여 출력하시오.\n",
    "# 이렇게 하는게 맞나?\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 주어진 데이터\n",
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "y_test = np.array([1, 1])  # 실제 데이터가 없으므로 임의로 설정\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 - 값은 바꾸심\n",
    "32. 영화 평점 이진분류 모델의 테스트 데이터 셋에 대한 혼동 행렬(confusion matrix)이 다 음과 같다. \n",
    "혼동 행렬의 숫자( 테스트 데이터 셋의 샘플 개수)는 다음과 같이 정의한다.\n",
    "∙TP (True Positive): 2 (실제 good이며 예측도 good)\n",
    "∙FN (False Negative): 1 (실제 good이지만 예측은 bad)\n",
    "∙FP (False Positive): 1 (실제 bad이지만 예측은 good) \n",
    "∙TN (True Negative): 1 (실제 bad이며 예측도 bad)\n",
    "##################################################################\n",
    "(1) 혼동 행렬을 사용하여 정확도(accuracy), 정밀도(Precision), 재현율(Recall)를 계산하시오.\n",
    "\n",
    "정밀도 : 실제로 양성으로 예측된 샘플 중에서 실제 양성의 비율\n",
    "Precision = TP / (TP+FP) = 2/3\n",
    "재현율 : 실제 양성 샘플 중에서 양성으로 예측된 샘플의 비율\n",
    "Recall= TP /(TP+FN) = 2/3\n",
    "정확도 : 실제 양성 샘플 중에서 양성으로 예측하고, 음성 샘플을 음성으로 예측된 샘플의 비율\n",
    "Recall= (TP+TN) /(TP+FP+TN+FN) = 3/5\n",
    "##################################################################\n",
    "(2) 다음 중 영화 평점 분류 모델에서 가장 적절한 평가 지표는? \n",
    "\n",
    "(a) 정확도 (b) 정밀도 \n",
    "(c) 재현율 (d) F1 점수\n",
    "\n",
    "(d) - 교수님 왈\n",
    "##################################################################\n",
    "(3) 다음 중 영화 평점 이진분류 모델에서 재현율이 높은 경우 어떤 상황을 의미하는가요? \n",
    "\n",
    "(a) 거짓 양성(FP)이 적은 경우 (b) 거짓 음성(FN)이 적은 경우\n",
    "(c) 실제 양성(TP)이 적은 경우 (d) 실제 음성(TN)이 적은 경우\n",
    "\n",
    "(b) - 교수님 왈\n",
    "##################################################################\n",
    "(4) 다음 중 영화 평점 이진분류 모델에서 발생할 수 있는 문제는? \n",
    "\n",
    "(a) 거짓 음성(FN)이 많은 경우 (b) 거짓 양성(FP)이 많은 경우\n",
    "(c) 실제 양성(TP)이 많은 경우 (d) 정확도(Accuracy)가 100%인 경우\n",
    "\n",
    "(a) - 교수님 왈"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
